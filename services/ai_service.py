"""
AI ë¶„ì„ ì„œë¹„ìŠ¤
ETF_AI ëª¨ë“ˆê³¼ ì—°ë™í•˜ì—¬ íˆ¬ì ê²°ì •ì„ ë¶„ì„í•˜ê³  ì•Œë¦¼ ì—¬ë¶€ë¥¼ ê²°ì •
"""

import httpx
import logging
from typing import Dict, Optional
from datetime import datetime, timedelta
import json

from config.notification_config import get_ai_analysis_threshold, NOTIFICATION_TYPES
from models import User, InvestmentSettings
from crud.notification import get_notifications_by_user_id_and_type

logger = logging.getLogger(__name__)

import os

# ETF_AI ì„œë¹„ìŠ¤ URL (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©)
AI_SERVICE_URL = os.getenv("ETF_AI_SERVICE_URL", "http://localhost:8001")
MAX_RETRIES = int(os.getenv("AI_SERVICE_MAX_RETRIES", "3"))
RETRY_DELAY = int(os.getenv("AI_SERVICE_RETRY_DELAY", "5"))

def create_integrated_analysis_messages(
    user: User,
    user_setting: InvestmentSettings,
    etf_data_list: list,
    market_news: str = None
) -> list:
    """
    ì‚¬ìš©ìì˜ ëª¨ë“  ETFë¥¼ í¬í•¨í•œ í†µí•© ë¶„ì„ ë©”ì‹œì§€ ìƒì„± (êµ¬ì¡°ì /êµ¬ì²´ì  í”„ë¡¬í”„íŠ¸)
    market_news: ì™¸ë¶€ ì‹œì¥ ë‰´ìŠ¤ ìš”ì•½(ì„ íƒ)
    """
    try:
        # 1. ì‚¬ìš©ì ì •ë³´
        user_info = f"""[ì‚¬ìš©ì ì •ë³´]\n- ì´ë¦„: {user.name}\n- ìœ„í—˜ ì„±í–¥(0~10): {user_setting.risk_level}\n- íˆ¬ì ëª©í‘œ/í˜ë¥´ì†Œë‚˜: {user_setting.persona or 'ë¯¸ì…ë ¥'}"""
        # 2. ETF ì •ë³´
        etf_info = "[ETF ëª©ë¡]\n" + "\n".join([
            f"- {etf_data['etf'].symbol}: {etf_data['etf_setting'].amount:,}ë§Œì›, ì£¼ê¸°: {etf_data['etf_setting'].cycle}, ì´ë¦„: {etf_data['etf'].name}"
            for etf_data in etf_data_list
        ])
        # 3. ì‹œì¥ ë‰´ìŠ¤
        news_info = f"[ì‹œì¥ ë‰´ìŠ¤]\n{market_news}" if market_news else "[ì‹œì¥ ë‰´ìŠ¤]\n(ìµœì‹  ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ)"
        # 4. ë¶„ì„ ê¸°ì¤€/ëª©í‘œ
        analysis_criteria = (
            "[ë¶„ì„ ê¸°ì¤€]\n"
            "- ì‹œì¥ ë³€ë™ì„±ì´ 20% ì´ìƒì´ê±°ë‚˜, ì‚¬ìš©ì ìœ„í—˜ ì„±í–¥ì´ 8 ì´ìƒì¼ ë•Œë§Œ ë¹„ì¤‘ ì¡°ì • ê¶Œê³ \n"
            "- ETFë³„ë¡œ ì¡°ì • ì‚¬ìœ ì™€ ê¶Œì¥ ë¹„ì¤‘ì„ ëª…í™•íˆ ì œì‹œ\n"
            "- íˆ¬ì ê¸ˆì•¡, ì£¼ê¸°, ì‹œì¥ ìƒí™©, ì‚¬ìš©ì ì„±í–¥ì„ ëª¨ë‘ ê³ ë ¤\n"
            "- ë¶ˆí•„ìš”í•œ ì¡°ì •ì€ í”¼í•˜ê³ , ë°˜ë“œì‹œ ì¡°ì •ì´ í•„ìš”í•œ ê²½ìš°ë§Œ ê¶Œê³ \n"
        )
        # 5. ì˜ˆì‹œ ë‹µë³€ í¬ë§·
        example_format = (
            "[ë¶„ì„ ê²°ê³¼ ì˜ˆì‹œ]\n"
            "- SPY: ë¹„ì¤‘ ìœ ì§€ (ì‹œì¥ ì•ˆì •, ì¶”ê°€ ë§¤ìˆ˜ ë¶ˆí•„ìš”)\n"
            "- QQQ: ë¹„ì¤‘ 10% ì¦ê°€ ê¶Œê³  (ê¸°ìˆ ì£¼ ê°•ì„¸, ì„±ì¥ ê¸°ëŒ€)\n"
            "- ì¢…í•© ì˜ê²¬: ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ì˜ ìœ„í—˜ë„ëŠ” ì ì • ìˆ˜ì¤€, ì¶”ê°€ ë¦¬ë°¸ëŸ°ì‹± í•„ìš” ì—†ìŒ\n"
        )
        # 6. ì˜¤ëŠ˜ ë‚ ì§œ
        today_date = f"[ë¶„ì„ ê¸°ì¤€ì¼] {datetime.now().year}ë…„ {datetime.now().month}ì›” {datetime.now().day}ì¼"
        # 7. ìµœì¢… developer ë©”ì‹œì§€ ì¡°ë¦½
        developer_content = (
            f"""
{user_info}\n\n{etf_info}\n\n{news_info}\n\n{analysis_criteria}\n{example_format}\n{today_date}\n\nìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì˜¤ëŠ˜ì˜ íˆ¬ì ì¡°ì–¸ì„ ìœ„ ì˜ˆì‹œ í¬ë§·ì— ë§ì¶° ì‘ì„±í•´ì¤˜.\nETFë³„ë¡œ ì¡°ì •ì´ í•„ìš”í•œ ê²½ìš° ê·¸ ì´ìœ ë¥¼ ë°˜ë“œì‹œ ëª…í™•íˆ ì„¤ëª…í•˜ê³ , ì¢…í•© ì˜ê²¬ë„ ê¼­ í¬í•¨í•´ì¤˜.\në‹µë³€ì€ ë°˜ë“œì‹œ [ë¶„ì„ ê²°ê³¼ ì˜ˆì‹œ] í¬ë§·ì„ ë”°ë¼ì¤˜.
"""
        )
        # 8. user ë©”ì‹œì§€(ëª…ë ¹)
        user_content = (
            "ì•„ë˜ ì •ë³´ë¥¼ ì°¸ê³ í•´ì„œ ì˜¤ëŠ˜ íˆ¬ìí•  ETF í¬íŠ¸í´ë¦¬ì˜¤ì˜ ê° ìƒí’ˆë³„ íˆ¬ì ë¹„ì¤‘ì„ ì¡°ì •í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨í•´ì¤˜. "
            "ì‹œì¥ ë‰´ìŠ¤, íˆ¬ì ê¸ˆì•¡, ì£¼ê¸°, ì‚¬ìš©ì ì„±í–¥ì„ ëª¨ë‘ ê³ ë ¤í•´ì„œ, ì¡°ì •ì´ í•„ìš”í•œ ê²½ìš°ë§Œ êµ¬ì²´ì ìœ¼ë¡œ ê¶Œê³ í•´ì¤˜. "
            "ETFë³„ë¡œ ì¡°ì • ì‚¬ìœ ì™€ ê¶Œì¥ ë¹„ì¤‘ì„ ëª…í™•íˆ ì œì‹œí•˜ê³ , ì¢…í•© ì˜ê²¬ë„ ê¼­ í¬í•¨í•´ì¤˜."
        )
        messages = [
            {"role": "developer", "content": developer_content},
            {"role": "user", "content": user_content}
        ]
        return messages
    except Exception as e:
        logger.error(f"âŒ í†µí•© ë¶„ì„ ë©”ì‹œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return []

async def request_ai_analysis(
    messages: list, 
    api_key: str, 
    model_type: str
) -> Optional[str]:
    """ETF_AI ì„œë¹„ìŠ¤ì— ë¶„ì„ ìš”ì²­ - analyze_sentiment í•¨ìˆ˜ ì‚¬ìš© (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    
    import asyncio
    
    for attempt in range(MAX_RETRIES):
        try:
            logger.info(f"ğŸ”„ AI ì„œë¹„ìŠ¤ ìš”ì²­ ì‹œë„ {attempt + 1}/{MAX_RETRIES}")
            
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    f"{AI_SERVICE_URL}/analyze",
                    json={
                        "messages": messages,
                        "api_key": api_key,
                        "model_type": model_type
                    }
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if result.get("success", False):
                        processing_time = result.get("processing_time", 0)
                        logger.info(f"âœ… AI ë¶„ì„ ì„±ê³µ (ì‹œë„ {attempt + 1}, ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ)")
                        return result.get("answer", "")
                    else:
                        error_msg = result.get('error', 'Unknown error')
                        logger.error(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨: {error_msg}")
                        return None
                else:
                    logger.error(f"âŒ AI ì„œë¹„ìŠ¤ HTTP ì˜¤ë¥˜: {response.status_code}")
                    if attempt < MAX_RETRIES - 1:
                        await asyncio.sleep(RETRY_DELAY)
                        continue
                    return None
                    
        except httpx.TimeoutException:
            logger.warning(f"â° AI ì„œë¹„ìŠ¤ íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1})")
            if attempt < MAX_RETRIES - 1:
                await asyncio.sleep(RETRY_DELAY)
                continue
            return None
            
        except httpx.ConnectError:
            logger.error(f"ğŸ”Œ AI ì„œë¹„ìŠ¤ ì—°ê²° ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}): {AI_SERVICE_URL}")
            if attempt < MAX_RETRIES - 1:
                await asyncio.sleep(RETRY_DELAY)
                continue
            return None
            
        except Exception as e:
            logger.error(f"âŒ AI ì„œë¹„ìŠ¤ ìš”ì²­ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}): {e}")
            if attempt < MAX_RETRIES - 1:
                await asyncio.sleep(RETRY_DELAY)
                continue
            return None
    
    logger.error(f"âŒ AI ì„œë¹„ìŠ¤ ìš”ì²­ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ ({MAX_RETRIES}íšŒ)")
    return None

async def request_batch_ai_analysis(
    analysis_requests: list
) -> list:
    """ETF_AI ì„œë¹„ìŠ¤ì— ë°°ì¹˜ ë¶„ì„ ìš”ì²­ - ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›"""
    
    import asyncio
    
    try:
        logger.info(f"ğŸ”„ ë°°ì¹˜ AI ë¶„ì„ ìš”ì²­ ì‹œì‘: {len(analysis_requests)}ê°œ")
        
        async with httpx.AsyncClient(timeout=120.0) as client:  # ë°°ì¹˜ ì²˜ë¦¬ì´ë¯€ë¡œ ë” ê¸´ íƒ€ì„ì•„ì›ƒ
            response = await client.post(
                f"{AI_SERVICE_URL}/analyze/batch",
                json={
                    "requests": [
                        {
                            "messages": req["messages"],
                            "api_key": req["api_key"],
                            "model_type": req["model_type"]
                        }
                        for req in analysis_requests
                    ]
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get("success", False):
                    summary = result.get("summary", {})
                    logger.info(f"âœ… ë°°ì¹˜ AI ë¶„ì„ ì„±ê³µ: {summary.get('successful_count', 0)}ê°œ ì„±ê³µ, {summary.get('failed_count', 0)}ê°œ ì‹¤íŒ¨, ì´ ì‹œê°„: {summary.get('total_processing_time', 0):.2f}ì´ˆ")
                    
                    # ì„±ê³µí•œ ê²°ê³¼ë“¤ë§Œ ë°˜í™˜
                    successful_results = result.get("results", {}).get("successful", [])
                    return [res.get("answer", "") for res in successful_results]
                else:
                    error_msg = result.get('error', 'Unknown error')
                    logger.error(f"âŒ ë°°ì¹˜ AI ë¶„ì„ ì‹¤íŒ¨: {error_msg}")
                    return []
            else:
                logger.error(f"âŒ ë°°ì¹˜ AI ì„œë¹„ìŠ¤ HTTP ì˜¤ë¥˜: {response.status_code}")
                return []
                
    except httpx.TimeoutException:
        logger.warning(f"â° ë°°ì¹˜ AI ì„œë¹„ìŠ¤ íƒ€ì„ì•„ì›ƒ")
        return []
        
    except httpx.ConnectError:
        logger.error(f"ğŸ”Œ ë°°ì¹˜ AI ì„œë¹„ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {AI_SERVICE_URL}")
        return []
        
    except Exception as e:
        logger.error(f"âŒ ë°°ì¹˜ AI ì„œë¹„ìŠ¤ ìš”ì²­ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return []

def determine_notification_need(analysis_result: str, previous_analysis: str = None) -> bool:
    """
    ë‹¤ì°¨ì› ë¶„ì„ê³¼ ML ë¶„ë¥˜ê¸°ë¥¼ í†µí•©í•œ ì•Œë¦¼ í•„ìš”ì„± íŒë‹¨
    
    Args:
        analysis_result: í˜„ì¬ AI ë¶„ì„ ê²°ê³¼
        previous_analysis: ì´ì „ AI ë¶„ì„ ê²°ê³¼
    
    Returns:
        ì•Œë¦¼ ì „ì†¡ ì—¬ë¶€
    """
    try:
        # 1. ê¸°ë³¸ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ë¶„ì„
        text_similarity = calculate_cosine_similarity(analysis_result, previous_analysis) if previous_analysis else 0.0
        
        # 2. íˆ¬ì ê¶Œì¥ì‚¬í•­ ë³€í™” ë¶„ì„
        recommendation_change = analyze_recommendation_change(analysis_result, previous_analysis)
        
        # 3. ìœ„í—˜ë„ ë³€í™” ë¶„ì„
        risk_change = analyze_risk_change(analysis_result, previous_analysis)
        
        # 4. íˆ¬ì ê¸ˆì•¡ ë³€í™” ë¶„ì„
        amount_change = analyze_investment_amount_change(analysis_result, previous_analysis)
        
        # 5. ì‹œì¥ ìƒí™© ë³€í™” ë¶„ì„
        market_change = analyze_market_situation_change(analysis_result, previous_analysis)
        
        # 6. ê°ì • ë³€í™” ë¶„ì„ (ì„ íƒì )
        sentiment_change = analyze_sentiment_change(analysis_result, previous_analysis)
        
        # 7. ê¸´ê¸‰ì„± ìˆ˜ì¤€ ë¶„ì„
        urgency_level = analyze_urgency_level(analysis_result)
        
        # 8. ML ë¶„ë¥˜ê¸° ë¶„ì„ (ì„ íƒì )
        ml_score = analyze_with_ml_classifier(analysis_result, previous_analysis)
        
        # 9. ì¢…í•© ì ìˆ˜ ê³„ì‚° (ê°œì„ ëœ ê°€ì¤‘ì¹˜)
        notification_score = calculate_enhanced_notification_score(
            text_similarity=text_similarity,
            recommendation_change=recommendation_change,
            risk_change=risk_change,
            amount_change=amount_change,
            market_change=market_change,
            sentiment_change=sentiment_change,
            urgency_level=urgency_level,
            ml_score=ml_score
        )
        
        # 10. ë™ì  ì„ê³„ê°’ ì ìš©
        dynamic_threshold = get_enhanced_dynamic_threshold(
            analysis_result, 
            urgency_level, 
            market_change
        )
        
        should_notify = notification_score > dynamic_threshold
        
        # ìƒì„¸ ë¡œê¹…
        logger.info(f"ğŸ“Š ê°œì„ ëœ ì•Œë¦¼ íŒë‹¨ ê²°ê³¼:")
        logger.info(f"   - í…ìŠ¤íŠ¸ ìœ ì‚¬ë„: {text_similarity:.3f}")
        logger.info(f"   - ê¶Œì¥ì‚¬í•­ ë³€í™”: {recommendation_change:.3f}")
        logger.info(f"   - ìœ„í—˜ë„ ë³€í™”: {risk_change:.3f}")
        logger.info(f"   - íˆ¬ìê¸ˆì•¡ ë³€í™”: {amount_change:.3f}")
        logger.info(f"   - ì‹œì¥ìƒí™© ë³€í™”: {market_change:.3f}")
        logger.info(f"   - ê°ì • ë³€í™”: {sentiment_change:.3f}")
        logger.info(f"   - ê¸´ê¸‰ì„± ìˆ˜ì¤€: {urgency_level:.3f}")
        logger.info(f"   - ML ë¶„ë¥˜ê¸° ì ìˆ˜: {ml_score:.3f}")
        logger.info(f"   - ì¢…í•© ì ìˆ˜: {notification_score:.3f}")
        logger.info(f"   - ë™ì  ì„ê³„ê°’: {dynamic_threshold:.3f}")
        logger.info(f"   - ì•Œë¦¼ ì „ì†¡: {'ì˜ˆ' if should_notify else 'ì•„ë‹ˆì˜¤'}")
        
        return should_notify
        
    except Exception as e:
        logger.error(f"âŒ ê°œì„ ëœ ì•Œë¦¼ íŒë‹¨ ì¤‘ ì˜¤ë¥˜: {e}")
        return True  # ì˜¤ë¥˜ ì‹œ ì•ˆì „í•˜ê²Œ ì•Œë¦¼ ì „ì†¡

def analyze_recommendation_change(current: str, previous: str = None) -> float:
    """íˆ¬ì ê¶Œì¥ì‚¬í•­ ë³€í™” ë¶„ì„"""
    try:
        if not previous:
            return 1.0  # ì´ì „ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìµœëŒ€ ë³€í™”ë¡œ ê°„ì£¼
        
        # ê¶Œì¥ì‚¬í•­ í‚¤ì›Œë“œ ì¶”ì¶œ
        current_recommendation = extract_recommendation(current)
        previous_recommendation = extract_recommendation(previous)
        
        # ê¶Œì¥ì‚¬í•­ ë³€í™” íŒ¨í„´ ë¶„ì„
        change_patterns = {
            'ë§¤ìˆ˜': ['ë§¤ìˆ˜', 'ì¦ê°€', 'ìƒí–¥', 'ì¶”ì²œ'],
            'ë§¤ë„': ['ë§¤ë„', 'ê°ì†Œ', 'í•˜í–¥', 'íšŒìˆ˜'],
            'ìœ ì§€': ['ìœ ì§€', 'ë³´ìœ ', 'í˜„ìƒìœ ì§€', 'ê´€ë§'],
            'ì¤‘ë¦½': ['ì¤‘ë¦½', 'ë³´ìˆ˜', 'ì‹ ì¤‘']
        }
        
        current_action = classify_recommendation_action(current_recommendation, change_patterns)
        previous_action = classify_recommendation_action(previous_recommendation, change_patterns)
        
        # ì•¡ì…˜ ë³€í™”ì— ë”°ë¥¸ ì ìˆ˜ ê³„ì‚°
        if current_action != previous_action:
            return 1.0  # ì•¡ì…˜ì´ ë°”ë€Œë©´ ìµœëŒ€ ë³€í™”
        elif current_action in ['ë§¤ìˆ˜', 'ë§¤ë„']:
            return 0.8  # ì ê·¹ì  ì•¡ì…˜ì€ ë†’ì€ ë³€í™”ë„
        else:
            return 0.3  # ë³´ìˆ˜ì  ì•¡ì…˜ì€ ë‚®ì€ ë³€í™”ë„
            
    except Exception as e:
        logger.error(f"âŒ ê¶Œì¥ì‚¬í•­ ë³€í™” ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.5

def analyze_risk_change(current: str, previous: str = None) -> float:
    """ìœ„í—˜ë„ ë³€í™” ë¶„ì„"""
    try:
        if not previous:
            return 0.5
        
        # ìœ„í—˜ë„ ê´€ë ¨ í‚¤ì›Œë“œ ì¶”ì¶œ
        risk_keywords = {
            'high_risk': ['ë†’ì€ ìœ„í—˜', 'ìœ„í—˜ë„ ì¦ê°€', 'ë¶ˆì•ˆì •', 'ë³€ë™ì„± ì¦ê°€'],
            'low_risk': ['ë‚®ì€ ìœ„í—˜', 'ì•ˆì •ì ', 'ë³´ìˆ˜ì ', 'ì•ˆì „'],
            'medium_risk': ['ë³´í†µ ìœ„í—˜', 'ì¤‘ê°„', 'ì ë‹¹í•œ']
        }
        
        current_risk = extract_risk_level(current, risk_keywords)
        previous_risk = extract_risk_level(previous, risk_keywords)
        
        # ìœ„í—˜ë„ ë³€í™” ê³„ì‚°
        risk_change = abs(current_risk - previous_risk)
        
        # ìœ„í—˜ë„ ë³€í™”ê°€ í´ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        return min(risk_change * 2, 1.0)
        
    except Exception as e:
        logger.error(f"âŒ ìœ„í—˜ë„ ë³€í™” ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.5

def analyze_investment_amount_change(current: str, previous: str = None) -> float:
    """íˆ¬ì ê¸ˆì•¡ ë³€í™” ë¶„ì„"""
    try:
        if not previous:
            return 0.5
        
        # ê¸ˆì•¡ ê´€ë ¨ ì •ë³´ ì¶”ì¶œ
        current_amounts = extract_investment_amounts(current)
        previous_amounts = extract_investment_amounts(previous)
        
        if not current_amounts or not previous_amounts:
            return 0.5
        
        # í‰ê·  ê¸ˆì•¡ ë³€í™”ìœ¨ ê³„ì‚°
        current_avg = sum(current_amounts) / len(current_amounts)
        previous_avg = sum(previous_amounts) / len(previous_amounts)
        
        if previous_avg == 0:
            return 0.5
        
        change_ratio = abs(current_avg - previous_avg) / previous_avg
        
        # ë³€í™”ìœ¨ì— ë”°ë¥¸ ì ìˆ˜ (20% ì´ìƒ ë³€í™” ì‹œ ë†’ì€ ì ìˆ˜)
        if change_ratio > 0.2:
            return 1.0
        elif change_ratio > 0.1:
            return 0.7
        else:
            return 0.3
            
    except Exception as e:
        logger.error(f"âŒ íˆ¬ì ê¸ˆì•¡ ë³€í™” ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.5

def analyze_market_situation_change(current: str, previous: str = None) -> float:
    """ì‹œì¥ ìƒí™© ë³€í™” ë¶„ì„"""
    try:
        if not previous:
            return 0.5
        
        # ì‹œì¥ ìƒí™© í‚¤ì›Œë“œ ì¶”ì¶œ
        market_keywords = {
            'bull_market': ['ìƒìŠ¹ì¥', 'í˜¸í™©', 'ê¸ì •ì ', 'ê¸°íšŒ'],
            'bear_market': ['í•˜ë½ì¥', 'ì¹¨ì²´', 'ë¶€ì •ì ', 'ìœ„í—˜'],
            'volatile': ['ë³€ë™ì„±', 'ë¶ˆì•ˆì •', 'ê¸‰ë³€', 'ì˜ˆì¸¡ë¶ˆê°€'],
            'stable': ['ì•ˆì •', 'í‰ì˜¨', 'ì˜ˆì¸¡ê°€ëŠ¥', 'ì¼ì •']
        }
        
        current_market = classify_market_situation(current, market_keywords)
        previous_market = classify_market_situation(previous, market_keywords)
        
        # ì‹œì¥ ìƒí™© ë³€í™”ì— ë”°ë¥¸ ì ìˆ˜
        if current_market != previous_market:
            return 1.0  # ì‹œì¥ ìƒí™©ì´ ë°”ë€Œë©´ ìµœëŒ€ ë³€í™”
        elif current_market in ['volatile', 'bear_market']:
            return 0.8  # ë¶ˆì•ˆì •í•œ ì‹œì¥ì€ ë†’ì€ ë³€í™”ë„
        else:
            return 0.4  # ì•ˆì •ì ì¸ ì‹œì¥ì€ ë‚®ì€ ë³€í™”ë„
            
    except Exception as e:
        logger.error(f"âŒ ì‹œì¥ ìƒí™© ë³€í™” ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.5

def calculate_notification_score(
    text_similarity: float,
    recommendation_change: float,
    risk_change: float,
    amount_change: float,
    market_change: float
) -> float:
    """ì¢…í•© ì•Œë¦¼ ì ìˆ˜ ê³„ì‚°"""
    try:
        # ê°€ì¤‘ì¹˜ ì„¤ì • (ì¤‘ìš”ë„ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥)
        weights = {
            'text_similarity': 0.2,      # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
            'recommendation_change': 0.3, # ê¶Œì¥ì‚¬í•­ ë³€í™” (ê°€ì¥ ì¤‘ìš”)
            'risk_change': 0.2,          # ìœ„í—˜ë„ ë³€í™”
            'amount_change': 0.15,       # íˆ¬ì ê¸ˆì•¡ ë³€í™”
            'market_change': 0.15        # ì‹œì¥ ìƒí™© ë³€í™”
        }
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        weighted_score = (
            (1 - text_similarity) * weights['text_similarity'] +
            recommendation_change * weights['recommendation_change'] +
            risk_change * weights['risk_change'] +
            amount_change * weights['amount_change'] +
            market_change * weights['market_change']
        )
        
        return min(weighted_score, 1.0)
        
    except Exception as e:
        logger.error(f"âŒ ì•Œë¦¼ ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.5

def get_dynamic_threshold(analysis_result: str) -> float:
    """ë™ì  ì„ê³„ê°’ ê³„ì‚°"""
    try:
        base_threshold = 0.7
        
        # ì‹œì¥ ìƒí™©ì— ë”°ë¥¸ ì„ê³„ê°’ ì¡°ì •
        if 'ê¸´ê¸‰' in analysis_result or 'ìœ„í—˜' in analysis_result:
            return base_threshold - 0.2  # ê¸´ê¸‰ ìƒí™©ì€ ë‚®ì€ ì„ê³„ê°’
        elif 'ì•ˆì •' in analysis_result or 'ê´€ë§' in analysis_result:
            return base_threshold + 0.1  # ì•ˆì •ì  ìƒí™©ì€ ë†’ì€ ì„ê³„ê°’
        
        # ì‹œê°„ëŒ€ì— ë”°ë¥¸ ì¡°ì • (ì‹œì¥ ê°œì¥ ì‹œê°„ ë“±)
        current_hour = datetime.now().hour
        if 9 <= current_hour <= 15:  # ì‹œì¥ ê°œì¥ ì‹œê°„
            return base_threshold - 0.1  # ì‹œì¥ ì‹œê°„ì—ëŠ” ë” ë¯¼ê°í•˜ê²Œ
        
        return base_threshold
        
    except Exception as e:
        logger.error(f"âŒ ë™ì  ì„ê³„ê°’ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.7

def classify_recommendation_action(recommendation: str, patterns: dict) -> str:
    """ê¶Œì¥ì‚¬í•­ì„ ì•¡ì…˜ìœ¼ë¡œ ë¶„ë¥˜"""
    try:
        recommendation_lower = recommendation.lower()
        
        for action, keywords in patterns.items():
            if any(keyword in recommendation_lower for keyword in keywords):
                return action
        
        return 'ì¤‘ë¦½'  # ê¸°ë³¸ê°’
        
    except Exception as e:
        logger.error(f"âŒ ê¶Œì¥ì‚¬í•­ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {e}")
        return 'ì¤‘ë¦½'

def extract_risk_level(text: str, risk_keywords: dict) -> float:
    """ìœ„í—˜ë„ ìˆ˜ì¤€ ì¶”ì¶œ (0.0 ~ 1.0)"""
    try:
        text_lower = text.lower()
        
        if any(keyword in text_lower for keyword in risk_keywords['high_risk']):
            return 0.8
        elif any(keyword in text_lower for keyword in risk_keywords['low_risk']):
            return 0.2
        elif any(keyword in text_lower for keyword in risk_keywords['medium_risk']):
            return 0.5
        
        return 0.5  # ê¸°ë³¸ê°’
        
    except Exception as e:
        logger.error(f"âŒ ìœ„í—˜ë„ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.5

def extract_investment_amounts(text: str) -> list:
    """íˆ¬ì ê¸ˆì•¡ ì¶”ì¶œ"""
    try:
        import re
        
        # ê¸ˆì•¡ íŒ¨í„´ ë§¤ì¹­ (ì˜ˆ: 100ë§Œì›, 1,000,000ì› ë“±)
        amount_patterns = [
            r'(\d+(?:,\d{3})*)\s*ë§Œì›',
            r'(\d+(?:,\d{3})*)\s*ì›',
            r'(\d+(?:,\d{3})*)\s*ì²œì›'
        ]
        
        amounts = []
        for pattern in amount_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                # ì‰¼í‘œ ì œê±° í›„ ìˆ«ìë¡œ ë³€í™˜
                amount_str = match.replace(',', '')
                try:
                    amount = float(amount_str)
                    amounts.append(amount)
                except ValueError:
                    continue
        
        return amounts
        
    except Exception as e:
        logger.error(f"âŒ íˆ¬ì ê¸ˆì•¡ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

def classify_market_situation(text: str, market_keywords: dict) -> str:
    """ì‹œì¥ ìƒí™© ë¶„ë¥˜"""
    try:
        text_lower = text.lower()
        
        for situation, keywords in market_keywords.items():
            if any(keyword in text_lower for keyword in keywords):
                return situation
        
        return 'stable'  # ê¸°ë³¸ê°’
        
    except Exception as e:
        logger.error(f"âŒ ì‹œì¥ ìƒí™© ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {e}")
        return 'stable'

def calculate_cosine_similarity(text1: str, text2: str) -> float:
    """
    ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    ETF_AIì™€ ë™ì¼í•œ SentenceTransformer ëª¨ë¸ ì‚¬ìš©
    """
    try:
        # SentenceTransformer ëª¨ë¸ ì‚¬ìš© (ETF_AIì™€ ë™ì¼)
        from sentence_transformers import SentenceTransformer
        from sklearn.metrics.pairwise import cosine_similarity
        
        # ëª¨ë¸ ë¡œë“œ (ìºì‹±ì„ ìœ„í•´ ì „ì—­ ë³€ìˆ˜ë¡œ ê´€ë¦¬)
        if not hasattr(calculate_cosine_similarity, 'model'):
            logger.info("ğŸ¤– SentenceTransformer ëª¨ë¸ ë¡œë”© ì¤‘...")
            calculate_cosine_similarity.model = SentenceTransformer('paraphrase-MiniLM-L6-v2')
            logger.info("âœ… SentenceTransformer ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        model = calculate_cosine_similarity.model
        
        # ê° ë¬¸ì¥ ì¸ì½”ë”©
        sent1_encode = model.encode([text1])
        sent2_encode = model.encode([text2])
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = cosine_similarity(sent1_encode, sent2_encode)
        
        result = similarity[0][0]
        logger.debug(f"ğŸ“Š ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {result:.3f}")
        
        return result
        
    except ImportError:
        logger.error("âŒ SentenceTransformerê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ë¶ˆê°€")
        return 0.0
        
    except Exception as e:
        logger.error(f"âŒ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.0  # ì˜¤ë¥˜ ì‹œ 0 ë°˜í™˜

def extract_recommendation(analysis_result: str) -> str:
    """AI ë¶„ì„ ê²°ê³¼ì—ì„œ ì¶”ì²œì‚¬í•­ ì¶”ì¶œ"""
    try:
        # ê°„ë‹¨í•œ ì¶”ì²œì‚¬í•­ ì¶”ì¶œ ë¡œì§
        lines = analysis_result.split('\n')
        for line in lines:
            if any(word in line for word in ["ì¶”ì²œ", "ê¶Œì¥", "ì œì•ˆ", "ì¡°ì •", "ë³€ê²½"]):
                return line.strip()
        
        # ì¶”ì²œ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì „ì²´ ê²°ê³¼ ë°˜í™˜ (ê¸¸ì´ ì œí•œ)
        if len(analysis_result) > 200:
            return analysis_result[:200] + "..."
        return analysis_result
        
    except Exception as e:
        logger.error(f"âŒ ì¶”ì²œì‚¬í•­ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return "AI ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

def extract_confidence_score(analysis_result: str) -> float:
    """AI ë¶„ì„ ê²°ê³¼ì—ì„œ ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ì¶œ (0.0 ~ 1.0)"""
    try:
        # ê°„ë‹¨í•œ ì‹ ë¢°ë„ ê³„ì‚° ë¡œì§
        confidence_score = 0.5  # ê¸°ë³¸ê°’
        
        # ë¶„ì„ ê²°ê³¼ì˜ ê¸¸ì´ì™€ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‹ ë¢°ë„ ì¡°ì •
        if len(analysis_result) > 100:
            confidence_score += 0.2
        
        if any(word in analysis_result for word in ["ë¶„ì„", "ë°ì´í„°", "ì •ë³´"]):
            confidence_score += 0.1
        
        if any(word in analysis_result for word in ["í™•ì‹¤", "ëª…í™•", "ë¶„ëª…"]):
            confidence_score += 0.1
        
        return min(confidence_score, 1.0)
        
    except Exception as e:
        logger.error(f"âŒ ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.5  # ê¸°ë³¸ê°’ ë°˜í™˜

def get_previous_analysis(user_id: int, etf_symbol: str, db) -> Optional[str]:
    """
    ì‚¬ìš©ìì˜ ì´ì „ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
    
    Args:
        user_id: ì‚¬ìš©ì ID
        etf_symbol: ETF ì‹¬ë³¼
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    
    Returns:
        ì´ì „ ë¶„ì„ ê²°ê³¼ ë˜ëŠ” None
    """
    try:
        # ìµœê·¼ AI ë¶„ì„ ì•Œë¦¼ ì¡°íšŒ
        notifications = get_notifications_by_user_id_and_type(
            db, user_id, NOTIFICATION_TYPES['AI_ANALYSIS'], limit=1
        )
        
        if notifications:
            # ì•Œë¦¼ ë‚´ìš©ì—ì„œ ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
            content = notifications[0].content
            return content
        
        return None
        
    except Exception as e:
        logger.error(f"âŒ ì´ì „ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def save_analysis_result(user_id: int, etf_symbol: str, analysis_result: str, db) -> bool:
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ì„ì‹œ ì €ì¥ (ì„ íƒì‚¬í•­)
    
    Args:
        user_id: ì‚¬ìš©ì ID
        etf_symbol: ETF ì‹¬ë³¼
        analysis_result: ë¶„ì„ ê²°ê³¼
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    
    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ì—¬ê¸°ì„œëŠ” ì•Œë¦¼ í…Œì´ë¸”ì— ì €ì¥í•˜ì§€ë§Œ, 
        # í•„ìš”ì‹œ ë³„ë„ì˜ ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”ì„ ë§Œë“¤ ìˆ˜ ìˆìŒ
        logger.info(f"ğŸ’¾ {user_id} ì‚¬ìš©ìì˜ {etf_symbol} ë¶„ì„ ê²°ê³¼ ì €ì¥ë¨")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        return False

def analyze_with_ml_classifier(analysis_result: str, previous_analysis: str = None) -> float:
    """
    ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ë¶„ë¥˜ê¸°ë¥¼ ì‚¬ìš©í•œ ì•Œë¦¼ í•„ìš”ì„± ë¶„ì„
    
    Args:
        analysis_result: í˜„ì¬ ë¶„ì„ ê²°ê³¼
        previous_analysis: ì´ì „ ë¶„ì„ ê²°ê³¼
    
    Returns:
        ML ë¶„ë¥˜ê¸° ì ìˆ˜ (0.0 ~ 1.0)
    """
    try:
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.ensemble import RandomForestClassifier
        import pickle
        import os
        
        # ML ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        model_path = "models/notification_classifier.pkl"
        vectorizer_path = "models/notification_vectorizer.pkl"
        
        # ëª¨ë¸ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(model_path) or not os.path.exists(vectorizer_path):
            logger.warning("ML ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë¶„ì„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return 0.5
        
        # ëª¨ë¸ ë¡œë“œ
        with open(model_path, 'rb') as f:
            classifier = pickle.load(f)
        
        with open(vectorizer_path, 'rb') as f:
            vectorizer = pickle.load(f)
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        combined_text = analysis_result
        if previous_analysis:
            combined_text += " " + previous_analysis
        
        # íŠ¹ì„± ì¶”ì¶œ
        features = vectorizer.transform([combined_text])
        
        # ì˜ˆì¸¡
        prediction = classifier.predict_proba(features)[0]
        
        # ì•Œë¦¼ í•„ìš”ì„± í™•ë¥  ë°˜í™˜ (í´ë˜ìŠ¤ 1ì˜ í™•ë¥ )
        return prediction[1] if len(prediction) > 1 else prediction[0]
        
    except Exception as e:
        logger.error(f"âŒ ML ë¶„ë¥˜ê¸° ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.5

def train_notification_classifier(training_data: list):
    """
    ì•Œë¦¼ í•„ìš”ì„± ë¶„ë¥˜ê¸° í›ˆë ¨
    
    Args:
        training_data: [(text, label), ...] í˜•íƒœì˜ í›ˆë ¨ ë°ì´í„°
    """
    try:
        from sklearn.feature_extraction.text import TfidfVectorizer
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.model_selection import train_test_split
        from sklearn.metrics import classification_report
        import pickle
        import os
        
        # ë°ì´í„° ë¶„ë¦¬
        texts = [item[0] for item in training_data]
        labels = [item[1] for item in training_data]
        
        # íŠ¹ì„± ì¶”ì¶œ
        vectorizer = TfidfVectorizer(
            max_features=1000,
            ngram_range=(1, 2),
            stop_words=None,
            min_df=2
        )
        
        X = vectorizer.fit_transform(texts)
        
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬
        X_train, X_test, y_train, y_test = train_test_split(
            X, labels, test_size=0.2, random_state=42
        )
        
        # ëª¨ë¸ í›ˆë ¨
        classifier = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
        
        classifier.fit(X_train, y_train)
        
        # ì„±ëŠ¥ í‰ê°€
        y_pred = classifier.predict(X_test)
        report = classification_report(y_test, y_pred)
        logger.info(f"ML ë¶„ë¥˜ê¸° ì„±ëŠ¥:\n{report}")
        
        # ëª¨ë¸ ì €ì¥
        os.makedirs("models", exist_ok=True)
        
        with open("models/notification_classifier.pkl", 'wb') as f:
            pickle.dump(classifier, f)
        
        with open("models/notification_vectorizer.pkl", 'wb') as f:
            pickle.dump(vectorizer, f)
        
        logger.info("âœ… ML ë¶„ë¥˜ê¸° í›ˆë ¨ ë° ì €ì¥ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ ML ë¶„ë¥˜ê¸° í›ˆë ¨ ì¤‘ ì˜¤ë¥˜: {e}")

def analyze_sentiment_change(current: str, previous: str = None) -> float:
    """
    ê°ì • ë¶„ì„ì„ í†µí•œ ë³€í™” ê°ì§€
    
    Args:
        current: í˜„ì¬ ë¶„ì„ ê²°ê³¼
        previous: ì´ì „ ë¶„ì„ ê²°ê³¼
    
    Returns:
        ê°ì • ë³€í™” ì ìˆ˜ (0.0 ~ 1.0)
    """
    try:
        from textblob import TextBlob
        
        # ê°ì • ì ìˆ˜ ê³„ì‚°
        current_sentiment = TextBlob(current).sentiment.polarity
        previous_sentiment = TextBlob(previous).sentiment.polarity if previous else 0.0
        
        # ê°ì • ë³€í™”ì˜ ì ˆëŒ“ê°’
        sentiment_change = abs(current_sentiment - previous_sentiment)
        
        # ê°ì • ë³€í™”ê°€ í´ìˆ˜ë¡ ë†’ì€ ì ìˆ˜ (0.5 ì´ìƒ ë³€í™” ì‹œ ë†’ì€ ì ìˆ˜)
        if sentiment_change > 0.5:
            return 1.0
        elif sentiment_change > 0.3:
            return 0.7
        elif sentiment_change > 0.1:
            return 0.4
        else:
            return 0.2
            
    except ImportError:
        logger.warning("TextBlobì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê°ì • ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return 0.5
    except Exception as e:
        logger.error(f"âŒ ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.5

def analyze_urgency_level(analysis_result: str) -> float:
    """
    ê¸´ê¸‰ì„± ìˆ˜ì¤€ ë¶„ì„
    
    Args:
        analysis_result: ë¶„ì„ ê²°ê³¼
    
    Returns:
        ê¸´ê¸‰ì„± ì ìˆ˜ (0.0 ~ 1.0)
    """
    try:
        urgency_keywords = {
            'high': ['ê¸´ê¸‰', 'ì¦‰ì‹œ', 'ë‹¹ì¥', 'ìœ„í—˜', 'ì£¼ì˜', 'ê²½ê³ '],
            'medium': ['ì‹ ì¤‘', 'ê´€ë§', 'ë³´ìˆ˜', 'ì ì§„ì '],
            'low': ['ì•ˆì •', 'í‰ì˜¨', 'ì¼ì •', 'ì˜ˆì¸¡ê°€ëŠ¥']
        }
        
        text_lower = analysis_result.lower()
        
        # ê¸´ê¸‰ì„± í‚¤ì›Œë“œ ë§¤ì¹­
        urgency_scores = {
            'high': sum(1 for keyword in urgency_keywords['high'] if keyword in text_lower),
            'medium': sum(1 for keyword in urgency_keywords['medium'] if keyword in text_lower),
            'low': sum(1 for keyword in urgency_keywords['low'] if keyword in text_lower)
        }
        
        # ê¸´ê¸‰ì„± ì ìˆ˜ ê³„ì‚°
        if urgency_scores['high'] > 0:
            return 1.0
        elif urgency_scores['medium'] > 0:
            return 0.6
        elif urgency_scores['low'] > 0:
            return 0.2
        else:
            return 0.5
            
    except Exception as e:
        logger.error(f"âŒ ê¸´ê¸‰ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.5

def calculate_enhanced_notification_score(
    text_similarity: float,
    recommendation_change: float,
    risk_change: float,
    amount_change: float,
    market_change: float,
    sentiment_change: float,
    urgency_level: float,
    ml_score: float
) -> float:
    """ê°œì„ ëœ ì¢…í•© ì•Œë¦¼ ì ìˆ˜ ê³„ì‚°"""
    try:
        # ê°€ì¤‘ì¹˜ ì„¤ì • (ì¤‘ìš”ë„ì™€ ì‹ ë¢°ë„ì— ë”°ë¼ ì¡°ì •)
        weights = {
            'text_similarity': 0.15,     # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„
            'recommendation_change': 0.25, # ê¶Œì¥ì‚¬í•­ ë³€í™” (ê°€ì¥ ì¤‘ìš”)
            'risk_change': 0.15,         # ìœ„í—˜ë„ ë³€í™”
            'amount_change': 0.10,       # íˆ¬ì ê¸ˆì•¡ ë³€í™”
            'market_change': 0.10,       # ì‹œì¥ ìƒí™© ë³€í™”
            'sentiment_change': 0.05,    # ê°ì • ë³€í™”
            'urgency_level': 0.10,       # ê¸´ê¸‰ì„± ìˆ˜ì¤€
            'ml_score': 0.10            # ML ë¶„ë¥˜ê¸° ì ìˆ˜
        }
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        weighted_score = (
            (1 - text_similarity) * weights['text_similarity'] +
            recommendation_change * weights['recommendation_change'] +
            risk_change * weights['risk_change'] +
            amount_change * weights['amount_change'] +
            market_change * weights['market_change'] +
            sentiment_change * weights['sentiment_change'] +
            urgency_level * weights['urgency_level'] +
            ml_score * weights['ml_score']
        )
        
        return min(weighted_score, 1.0)
        
    except Exception as e:
        logger.error(f"âŒ ê°œì„ ëœ ì•Œë¦¼ ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.5

def get_enhanced_dynamic_threshold(
    analysis_result: str, 
    urgency_level: float, 
    market_change: float
) -> float:
    """ê°œì„ ëœ ë™ì  ì„ê³„ê°’ ê³„ì‚°"""
    try:
        base_threshold = 0.7
        
        # ê¸´ê¸‰ì„±ì— ë”°ë¥¸ ì„ê³„ê°’ ì¡°ì •
        if urgency_level > 0.8:
            base_threshold -= 0.3  # ê¸´ê¸‰ ìƒí™©ì€ ë§¤ìš° ë‚®ì€ ì„ê³„ê°’
        elif urgency_level > 0.6:
            base_threshold -= 0.2  # ë†’ì€ ê¸´ê¸‰ì„±
        elif urgency_level > 0.4:
            base_threshold -= 0.1  # ì¤‘ê°„ ê¸´ê¸‰ì„±
        
        # ì‹œì¥ ìƒí™©ì— ë”°ë¥¸ ì¡°ì •
        if market_change > 0.8:
            base_threshold -= 0.2  # ì‹œì¥ ê¸‰ë³€ ì‹œ ë‚®ì€ ì„ê³„ê°’
        elif 'ë¶ˆì•ˆì •' in analysis_result or 'ë³€ë™ì„±' in analysis_result:
            base_threshold -= 0.1
        
        # ì‹œê°„ëŒ€ì— ë”°ë¥¸ ì¡°ì •
        current_hour = datetime.now().hour
        if 9 <= current_hour <= 15:  # ì‹œì¥ ê°œì¥ ì‹œê°„
            base_threshold -= 0.1
        elif 15 < current_hour <= 18:  # ì‹œì¥ ë§ˆê° í›„
            base_threshold += 0.05
        
        # ìš”ì¼ì— ë”°ë¥¸ ì¡°ì •
        current_weekday = datetime.now().weekday()
        if current_weekday in [5, 6]:  # ì£¼ë§
            base_threshold += 0.1  # ì£¼ë§ì—ëŠ” í›¨ì”¬ ëœ ë¯¼ê°í•˜ê²Œ
        
        # ìµœì†Œ/ìµœëŒ€ ì„ê³„ê°’ ë³´ì¥
        return max(0.3, min(0.9, base_threshold))
        
    except Exception as e:
        logger.error(f"âŒ ê°œì„ ëœ ë™ì  ì„ê³„ê°’ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.7

def get_user_customized_threshold(user_id: int, db) -> float:
    """
    ì‚¬ìš©ìë³„ ë§ì¶¤í˜• ì•Œë¦¼ ì„ê³„ê°’ ê³„ì‚°
    
    Args:
        user_id: ì‚¬ìš©ì ID
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    
    Returns:
        ì‚¬ìš©ìë³„ ì„ê³„ê°’
    """
    try:
        from crud.user import get_user_by_id
        from crud.notification import get_user_notification_history
        
        user = get_user_by_id(db, user_id)
        if not user or not user.settings:
            return 0.7  # ê¸°ë³¸ê°’
        
        # ì‚¬ìš©ì ìœ„í—˜ë„ì— ë”°ë¥¸ ê¸°ë³¸ ì„ê³„ê°’ ì¡°ì •
        risk_level = user.settings.risk_level
        base_threshold = 0.7
        
        if risk_level <= 3:  # ë³´ìˆ˜ì  íˆ¬ìì
            base_threshold += 0.1  # ë” ë†’ì€ ì„ê³„ê°’ (ì ì€ ì•Œë¦¼)
        elif risk_level >= 7:  # ê³µê²©ì  íˆ¬ìì
            base_threshold -= 0.1  # ë” ë‚®ì€ ì„ê³„ê°’ (ë§ì€ ì•Œë¦¼)
        
        # ì‚¬ìš©ì ì•Œë¦¼ ì´ë ¥ ë¶„ì„
        notification_history = get_user_notification_history(db, user_id, limit=10)
        
        if notification_history:
            # ìµœê·¼ ì•Œë¦¼ ë¹ˆë„ ë¶„ì„
            recent_notifications = len([n for n in notification_history if n.created_at > datetime.now() - timedelta(days=7)])
            
            if recent_notifications > 5:  # ì¼ì£¼ì¼ ë‚´ 5ê°œ ì´ìƒ ì•Œë¦¼
                base_threshold += 0.1  # ì•Œë¦¼ ë¹ˆë„ê°€ ë†’ìœ¼ë©´ ì„ê³„ê°’ ì¦ê°€
            elif recent_notifications < 2:  # ì¼ì£¼ì¼ ë‚´ 2ê°œ ë¯¸ë§Œ ì•Œë¦¼
                base_threshold -= 0.05  # ì•Œë¦¼ ë¹ˆë„ê°€ ë‚®ìœ¼ë©´ ì„ê³„ê°’ ê°ì†Œ
        
        # ì‚¬ìš©ì íˆ¬ì íŒ¨í„´ ë¶„ì„
        investment_pattern = analyze_user_investment_pattern(user_id, db)
        
        if investment_pattern == 'frequent':
            base_threshold -= 0.05  # ìì£¼ íˆ¬ìí•˜ëŠ” ì‚¬ìš©ìëŠ” ë” ë¯¼ê°í•˜ê²Œ
        elif investment_pattern == 'conservative':
            base_threshold += 0.05  # ë³´ìˆ˜ì  íˆ¬ììëŠ” ëœ ë¯¼ê°í•˜ê²Œ
        
        return max(0.3, min(0.9, base_threshold))
        
    except Exception as e:
        logger.error(f"âŒ ì‚¬ìš©ì ë§ì¶¤í˜• ì„ê³„ê°’ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.7

def analyze_user_investment_pattern(user_id: int, db) -> str:
    """
    ì‚¬ìš©ì íˆ¬ì íŒ¨í„´ ë¶„ì„
    
    Args:
        user_id: ì‚¬ìš©ì ID
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    
    Returns:
        íˆ¬ì íŒ¨í„´ ('frequent', 'moderate', 'conservative')
    """
    try:
        from crud.etf import get_investment_etf_settings_by_user_id
        
        etf_settings = get_investment_etf_settings_by_user_id(db, user_id)
        
        if not etf_settings:
            return 'moderate'
        
        # íˆ¬ì ì£¼ê¸° ë¶„ì„
        daily_count = sum(1 for setting in etf_settings if setting.cycle == 'daily')
        weekly_count = sum(1 for setting in etf_settings if setting.cycle == 'weekly')
        monthly_count = sum(1 for setting in etf_settings if setting.cycle == 'monthly')
        
        # ì´ íˆ¬ì ê¸ˆì•¡ ë¶„ì„
        total_amount = sum(setting.amount for setting in etf_settings)
        
        # íŒ¨í„´ ë¶„ë¥˜
        if daily_count > 0 or (weekly_count > 2 and total_amount > 100):
            return 'frequent'  # ìì£¼ íˆ¬ìí•˜ëŠ” íŒ¨í„´
        elif monthly_count > 0 and total_amount < 50:
            return 'conservative'  # ë³´ìˆ˜ì  íˆ¬ì íŒ¨í„´
        else:
            return 'moderate'  # ë³´í†µ íˆ¬ì íŒ¨í„´
            
    except Exception as e:
        logger.error(f"âŒ ì‚¬ìš©ì íˆ¬ì íŒ¨í„´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        return 'moderate'

def get_context_aware_threshold(
    analysis_result: str,
    user_id: int,
    etf_symbol: str,
    db
) -> float:
    """
    ìƒí™© ì¸ì‹ ì„ê³„ê°’ ê³„ì‚°
    
    Args:
        analysis_result: ë¶„ì„ ê²°ê³¼
        user_id: ì‚¬ìš©ì ID
        etf_symbol: ETF ì‹¬ë³¼
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    
    Returns:
        ìƒí™© ì¸ì‹ ì„ê³„ê°’
    """
    try:
        # ê¸°ë³¸ ì‚¬ìš©ì ë§ì¶¤í˜• ì„ê³„ê°’
        user_threshold = get_user_customized_threshold(user_id, db)
        
        # ETFë³„ íŠ¹ì„±ì— ë”°ë¥¸ ì¡°ì •
        etf_adjustment = get_etf_specific_adjustment(etf_symbol)
        
        # ì‹œì¥ ìƒí™©ì— ë”°ë¥¸ ì¡°ì •
        market_adjustment = get_market_situation_adjustment(analysis_result)
        
        # ì‹œê°„ëŒ€ë³„ ì¡°ì •
        time_adjustment = get_time_based_adjustment()
        
        # ìµœì¢… ì„ê³„ê°’ ê³„ì‚°
        final_threshold = user_threshold + etf_adjustment + market_adjustment + time_adjustment
        
        return max(0.3, min(0.9, final_threshold))
        
    except Exception as e:
        logger.error(f"âŒ ìƒí™© ì¸ì‹ ì„ê³„ê°’ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.7

def get_etf_specific_adjustment(etf_symbol: str) -> float:
    """ETFë³„ íŠ¹ì„±ì— ë”°ë¥¸ ì„ê³„ê°’ ì¡°ì •"""
    try:
        # ë³€ë™ì„±ì´ ë†’ì€ ETFëŠ” ë” ë¯¼ê°í•˜ê²Œ
        high_volatility_etfs = ['QQQ', 'TQQQ', 'SQQQ', 'VXX']
        low_volatility_etfs = ['BND', 'TLT', 'GLD', 'VNQ']
        
        if etf_symbol in high_volatility_etfs:
            return -0.1  # ë‚®ì€ ì„ê³„ê°’ (ë” ë¯¼ê°í•˜ê²Œ)
        elif etf_symbol in low_volatility_etfs:
            return 0.05  # ë†’ì€ ì„ê³„ê°’ (ëœ ë¯¼ê°í•˜ê²Œ)
        
        return 0.0
        
    except Exception as e:
        logger.error(f"âŒ ETFë³„ ì¡°ì • ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.0

def get_market_situation_adjustment(analysis_result: str) -> float:
    """ì‹œì¥ ìƒí™©ì— ë”°ë¥¸ ì„ê³„ê°’ ì¡°ì •"""
    try:
        adjustment = 0.0
        
        # ê¸´ê¸‰ ìƒí™© í‚¤ì›Œë“œ
        urgent_keywords = ['ê¸´ê¸‰', 'ìœ„í—˜', 'ì£¼ì˜', 'ê²½ê³ ', 'ì¦‰ì‹œ']
        if any(keyword in analysis_result for keyword in urgent_keywords):
            adjustment -= 0.2
        
        # ì•ˆì •ì  ìƒí™© í‚¤ì›Œë“œ
        stable_keywords = ['ì•ˆì •', 'í‰ì˜¨', 'ê´€ë§', 'ë³´ìˆ˜']
        if any(keyword in analysis_result for keyword in stable_keywords):
            adjustment += 0.1
        
        return adjustment
        
    except Exception as e:
        logger.error(f"âŒ ì‹œì¥ ìƒí™© ì¡°ì • ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.0

def get_time_based_adjustment() -> float:
    """ì‹œê°„ëŒ€ë³„ ì„ê³„ê°’ ì¡°ì •"""
    try:
        current_time = datetime.now()
        current_hour = current_time.hour
        current_weekday = current_time.weekday()
        
        adjustment = 0.0
        
        # ì‹œì¥ ê°œì¥ ì‹œê°„ (9-15ì‹œ)
        if 9 <= current_hour <= 15:
            adjustment -= 0.1  # ì‹œì¥ ì‹œê°„ì—ëŠ” ë” ë¯¼ê°í•˜ê²Œ
        
        # ì‹œì¥ ë§ˆê° í›„ (15-18ì‹œ)
        elif 15 < current_hour <= 18:
            adjustment += 0.05  # ë§ˆê° í›„ì—ëŠ” ëœ ë¯¼ê°í•˜ê²Œ
        
        # ì•¼ê°„ ì‹œê°„ (18-9ì‹œ)
        elif current_hour > 18 or current_hour < 9:
            adjustment += 0.1  # ì•¼ê°„ì—ëŠ” ëœ ë¯¼ê°í•˜ê²Œ
        
        # ì£¼ë§
        if current_weekday in [5, 6]:  # í† , ì¼
            adjustment += 0.15  # ì£¼ë§ì—ëŠ” í›¨ì”¬ ëœ ë¯¼ê°í•˜ê²Œ
        
        return adjustment
        
    except Exception as e:
        logger.error(f"âŒ ì‹œê°„ëŒ€ë³„ ì¡°ì • ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.0