"""
AI ë¶„ì„ ì„œë¹„ìŠ¤
ETF_AI ëª¨ë“ˆê³¼ ì—°ë™í•˜ì—¬ íˆ¬ì ê²°ì •ì„ ë¶„ì„í•˜ê³  ì•Œë¦¼ ì—¬ë¶€ë¥¼ ê²°ì •
"""

import httpx
import logging
from typing import Dict, Optional
from datetime import datetime
import json

from config.notification_config import get_ai_analysis_threshold, NOTIFICATION_TYPES
from models import User, InvestmentSettings
from crud.notification import get_user_notifications_by_type

logger = logging.getLogger(__name__)

import os

# ETF_AI ì„œë¹„ìŠ¤ URL (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©)
AI_SERVICE_URL = os.getenv("ETF_AI_SERVICE_URL", "http://localhost:8001")
MAX_RETRIES = int(os.getenv("AI_SERVICE_MAX_RETRIES", "3"))
RETRY_DELAY = int(os.getenv("AI_SERVICE_RETRY_DELAY", "5"))

def create_integrated_analysis_messages(
    user: User,
    user_setting: InvestmentSettings,
    etf_data_list: list
) -> list:
    """ì‚¬ìš©ìì˜ ëª¨ë“  ETFë¥¼ í¬í•¨í•œ í†µí•© ë¶„ì„ ë©”ì‹œì§€ ìƒì„±"""
    
    try:
        # ì‚¬ìš©ì ì •ë³´
        user_name = user.name
        invest_type = user_setting.risk_level
        interest = user_setting.persona or "ETF íˆ¬ì"
        
        # ETF ì •ë³´ ìš”ì•½ ìƒì„±
        etf_summary = []
        
        for etf_data in etf_data_list:
            etf_setting = etf_data['etf_setting']
            etf = etf_data['etf']
            
            etf_summary.append(f"{etf.symbol}: {etf.name} - {etf_setting.amount:,}ë§Œì›")
        
        # ì˜¤ëŠ˜ ë‚ ì§œ ì •ë³´
        today_date = f"{datetime.now().year}ë…„ {datetime.now().month}ì›” {datetime.now().day}ì¼"
        today_etfs = ", ".join([f"{etf_data['etf'].symbol}" for etf_data in etf_data_list])
        today_etfs_invest_price = ", ".join([f"{etf_data['etf_setting'].amount:,}ë§Œì›" for etf_data in etf_data_list])
        
        # analyze_instructions ìŠ¤íƒ€ì¼ë¡œ developer ë©”ì‹œì§€ ìƒì„±
        developer_content = f"ë„ˆì˜ ì´ë¦„ì€ ê¸ˆìœµ Agentì•¼. ì‚¬ìš©ìë¥¼ '{user_name} ê³ ê°ë‹˜'ì´ë¼ê³  ë¶ˆëŸ¬ì•¼ í•´.\
        ë„ˆê°€ í•´ì•¼í•˜ëŠ” ì—…ë¬´ëŠ” ì‚¬ìš©ìì˜ ì„±í–¥ê³¼ ìµœê·¼ ë‰´ìŠ¤ ë° í•œêµ­ ì€í–‰ì—ì„œ ì œê³µí•˜ëŠ” í•´ì™¸ ë™í–¥ë¶„ì„, í˜„ì§€ì •ë³´ ìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í¬íŠ¸í´ë¦¬ì˜¤ ì „ì²´ë¥¼ ë¶„ì„í•´ì„œ '{user_name} ê³ ê°ë‹˜, ì˜¤ëŠ˜ íˆ¬ìí•  ETF í¬íŠ¸í´ë¦¬ì˜¤ì˜ ì „ë§ì´ ì´ëŸ¬ë‹ˆ ê° ìƒí’ˆë³„ë¡œ íˆ¬ì ë¹„ì¤‘ì„ ì¡°ì •í•˜ëŠ”ê²Œ ì¢‹ê² ë‹¤.'ë¼ê³  ë§í•´ì¤˜ì•¼í•´.\
        ì˜¤ëŠ˜ ë‚ ì§œëŠ” {today_date}ì•¼.\
        ì‚¬ìš©ìì˜ íˆ¬ì ì„±í–¥ì€ 0(ë³´ìˆ˜ì ) ~ 10(ê³µê²©ì )ì´ë¼ê³  í•  ë•Œ, {invest_type}ì´ì•¼.\
        ì‚¬ìš©ìê°€ ì˜¤ëŠ˜ íˆ¬ìí•  ETF í¬íŠ¸í´ë¦¬ì˜¤ ì •ë³´ëŠ” {', '.join(etf_summary)}ì•¼."
        
        messages = [
            {
                "role": "developer",
                "content": developer_content
            },
            {
                "role": "user",
                "content": f"ë„¤ì´ë²„ ê¸€ë¡œë²Œ ê²½ì œ ë‰´ìŠ¤, ë„¤ì´ë²„ í•œêµ­ ê²½ì œ ë‰´ìŠ¤, í•œêµ­ì€í–‰ì—ì„œ ì œê³µí•˜ëŠ” ì •ë³´ 3ê°€ì§€ë¥¼ ëª¨ë‘ ë¶„ì„í•´ì¤˜.\
                            ì˜¤ëŠ˜ ë‚˜ëŠ” {today_etfs} ETF í¬íŠ¸í´ë¦¬ì˜¤ì— ê°ê° {today_etfs_invest_price}ì”©ì„ íˆ¬ìí•˜ëŠ” ë‚ ì´ì•¼.\
                            ê° ETFë³„ë¡œ í˜„ì¬ ì‹œì¥ ìƒí™©ì„ ë¶„ì„í•˜ê³ , íˆ¬ì ë¹„ìœ¨ ì¡°ì •ì´ í•„ìš”í•œ ìƒí’ˆì´ ìˆëŠ”ì§€ íŒë‹¨í•´ì¤˜.\
                            ìš”ì•½ë§Œ ê°„ê²°í•˜ê²Œ í•´ì„œ ê° ìƒí’ˆë³„ íˆ¬ì ë¹„ìœ¨ì„ ì¡°ì •í•´ì„œ ìµœì¢… íˆ¬ì ê¸ˆì•¡ì„ ë„ì¶œí•´ì¤˜."
            }
        ]
        
        return messages
        
    except Exception as e:
        logger.error(f"âŒ í†µí•© ë¶„ì„ ë©”ì‹œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return []

async def request_ai_analysis(
    messages: list, 
    api_key: str, 
    model_type: str
) -> Optional[str]:
    """ETF_AI ì„œë¹„ìŠ¤ì— ë¶„ì„ ìš”ì²­ - analyze_sentiment í•¨ìˆ˜ ì‚¬ìš© (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    
    import asyncio
    
    for attempt in range(MAX_RETRIES):
        try:
            logger.info(f"ğŸ”„ AI ì„œë¹„ìŠ¤ ìš”ì²­ ì‹œë„ {attempt + 1}/{MAX_RETRIES}")
            
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(
                    f"{AI_SERVICE_URL}/analyze",
                    json={
                        "messages": messages,
                        "api_key": api_key,
                        "model_type": model_type
                    }
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if result.get("success", False):
                        processing_time = result.get("processing_time", 0)
                        logger.info(f"âœ… AI ë¶„ì„ ì„±ê³µ (ì‹œë„ {attempt + 1}, ì²˜ë¦¬ì‹œê°„: {processing_time:.2f}ì´ˆ)")
                        return result.get("answer", "")
                    else:
                        error_msg = result.get('error', 'Unknown error')
                        logger.error(f"âŒ AI ë¶„ì„ ì‹¤íŒ¨: {error_msg}")
                        return None
                else:
                    logger.error(f"âŒ AI ì„œë¹„ìŠ¤ HTTP ì˜¤ë¥˜: {response.status_code}")
                    if attempt < MAX_RETRIES - 1:
                        await asyncio.sleep(RETRY_DELAY)
                        continue
                    return None
                    
        except httpx.TimeoutException:
            logger.warning(f"â° AI ì„œë¹„ìŠ¤ íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1})")
            if attempt < MAX_RETRIES - 1:
                await asyncio.sleep(RETRY_DELAY)
                continue
            return None
            
        except httpx.ConnectError:
            logger.error(f"ğŸ”Œ AI ì„œë¹„ìŠ¤ ì—°ê²° ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}): {AI_SERVICE_URL}")
            if attempt < MAX_RETRIES - 1:
                await asyncio.sleep(RETRY_DELAY)
                continue
            return None
            
        except Exception as e:
            logger.error(f"âŒ AI ì„œë¹„ìŠ¤ ìš”ì²­ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}): {e}")
            if attempt < MAX_RETRIES - 1:
                await asyncio.sleep(RETRY_DELAY)
                continue
            return None
    
    logger.error(f"âŒ AI ì„œë¹„ìŠ¤ ìš”ì²­ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼ ({MAX_RETRIES}íšŒ)")
    return None

async def request_batch_ai_analysis(
    analysis_requests: list
) -> list:
    """ETF_AI ì„œë¹„ìŠ¤ì— ë°°ì¹˜ ë¶„ì„ ìš”ì²­ - ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›"""
    
    import asyncio
    
    try:
        logger.info(f"ğŸ”„ ë°°ì¹˜ AI ë¶„ì„ ìš”ì²­ ì‹œì‘: {len(analysis_requests)}ê°œ")
        
        async with httpx.AsyncClient(timeout=120.0) as client:  # ë°°ì¹˜ ì²˜ë¦¬ì´ë¯€ë¡œ ë” ê¸´ íƒ€ì„ì•„ì›ƒ
            response = await client.post(
                f"{AI_SERVICE_URL}/analyze/batch",
                json={
                    "requests": [
                        {
                            "messages": req["messages"],
                            "api_key": req["api_key"],
                            "model_type": req["model_type"]
                        }
                        for req in analysis_requests
                    ]
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get("success", False):
                    summary = result.get("summary", {})
                    logger.info(f"âœ… ë°°ì¹˜ AI ë¶„ì„ ì„±ê³µ: {summary.get('successful_count', 0)}ê°œ ì„±ê³µ, {summary.get('failed_count', 0)}ê°œ ì‹¤íŒ¨, ì´ ì‹œê°„: {summary.get('total_processing_time', 0):.2f}ì´ˆ")
                    
                    # ì„±ê³µí•œ ê²°ê³¼ë“¤ë§Œ ë°˜í™˜
                    successful_results = result.get("results", {}).get("successful", [])
                    return [res.get("answer", "") for res in successful_results]
                else:
                    error_msg = result.get('error', 'Unknown error')
                    logger.error(f"âŒ ë°°ì¹˜ AI ë¶„ì„ ì‹¤íŒ¨: {error_msg}")
                    return []
            else:
                logger.error(f"âŒ ë°°ì¹˜ AI ì„œë¹„ìŠ¤ HTTP ì˜¤ë¥˜: {response.status_code}")
                return []
                
    except httpx.TimeoutException:
        logger.warning(f"â° ë°°ì¹˜ AI ì„œë¹„ìŠ¤ íƒ€ì„ì•„ì›ƒ")
        return []
        
    except httpx.ConnectError:
        logger.error(f"ğŸ”Œ ë°°ì¹˜ AI ì„œë¹„ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {AI_SERVICE_URL}")
        return []
        
    except Exception as e:
        logger.error(f"âŒ ë°°ì¹˜ AI ì„œë¹„ìŠ¤ ìš”ì²­ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return []

def determine_notification_need(analysis_result: str, previous_analysis: str = None) -> bool:
    """
    AI ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì•Œë¦¼ ì „ì†¡ ì—¬ë¶€ ê²°ì •
    ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ì´ì „ ë¶„ì„ê³¼ ë¹„êµí•˜ì—¬ ë³€í™” ê°ì§€
    
    Args:
        analysis_result: AI ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸
        previous_analysis: ì´ì „ ë¶„ì„ ê²°ê³¼ í…ìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
    
    Returns:
        ì•Œë¦¼ ì „ì†¡ ì—¬ë¶€ (True/False)
    """
    try:
        # ì´ì „ ë¶„ì„ì´ ìˆëŠ” ê²½ìš° ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ íŒë‹¨
        if previous_analysis:
            similarity = calculate_cosine_similarity(previous_analysis, analysis_result)
            similarity_threshold = 0.45  # ETF_AIì™€ ë™ì¼í•œ ì„ê³„ê°’
            
            should_notify = similarity < similarity_threshold
            
            logger.info(f"ğŸ“Š ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {similarity:.3f}, ì„ê³„ê°’: {similarity_threshold}, ì•Œë¦¼ ì „ì†¡: {should_notify}")
            
            return should_notify
        
        # ì´ì „ ë¶„ì„ì´ ì—†ëŠ” ê²½ìš° í‚¤ì›Œë“œ ê¸°ë°˜ íŒë‹¨ (ê¸°ì¡´ ë°©ì‹)
        threshold = get_ai_analysis_threshold()
        
        # ë¶„ì„ ê²°ê³¼ì—ì„œ íˆ¬ì ë³€ê²½ í•„ìš”ì„± í‚¤ì›Œë“œ í™•ì¸
        change_keywords = [
            "ì¡°ì •", "ë³€ê²½", "ìˆ˜ì •", "ì¡°ì •í•´ì•¼", "ë³€ê²½í•´ì•¼", "ìˆ˜ì •í•´ì•¼",
            "ë¹„ì¤‘ ì¡°ì •", "íˆ¬ì ë¹„ìœ¨ ì¡°ì •", "ê¸ˆì•¡ ì¡°ì •",
            "ì¶”ê°€ íˆ¬ì", "íˆ¬ì ê¸ˆì•¡ ì¦ê°€", "íˆ¬ì ê¸ˆì•¡ ê°ì†Œ",
            "ê¶Œì¥", "ì¶”ì²œ", "ì œì•ˆ"
        ]
        
        # ë¶„ì„ ê²°ê³¼ì—ì„œ ë³€ê²½ í•„ìš”ì„± ì ìˆ˜ ê³„ì‚°
        change_score = 0.0
        
        for keyword in change_keywords:
            if keyword in analysis_result:
                change_score += 0.1  # ê° í‚¤ì›Œë“œë‹¹ 0.1ì 
        
        # ê¸ˆì•¡ ë³€ê²½ì´ ì–¸ê¸‰ëœ ê²½ìš° ì¶”ê°€ ì ìˆ˜
        if any(word in analysis_result for word in ["ì›", "ê¸ˆì•¡", "íˆ¬ìì•¡"]):
            change_score += 0.2
        
        # ë¹„ì¤‘ ì¡°ì •ì´ ì–¸ê¸‰ëœ ê²½ìš° ì¶”ê°€ ì ìˆ˜
        if any(word in analysis_result for word in ["ë¹„ì¤‘", "ë¹„ìœ¨", "%"]):
            change_score += 0.3
        
        # ì„ê³„ê°’ê³¼ ë¹„êµ
        should_notify = change_score >= threshold
        
        logger.info(f"ğŸ“Š í‚¤ì›Œë“œ ê¸°ë°˜ ì ìˆ˜: {change_score:.2f}, ì„ê³„ê°’: {threshold}, ì•Œë¦¼ ì „ì†¡: {should_notify}")
        
        return should_notify
        
    except Exception as e:
        logger.error(f"âŒ ì•Œë¦¼ í•„ìš”ì„± íŒë‹¨ ì¤‘ ì˜¤ë¥˜: {e}")
        return False  # ì˜¤ë¥˜ ì‹œ ì•Œë¦¼ ì „ì†¡í•˜ì§€ ì•ŠìŒ

def calculate_cosine_similarity(text1: str, text2: str) -> float:
    """
    ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    ETF_AIì™€ ë™ì¼í•œ SentenceTransformer ëª¨ë¸ ì‚¬ìš©
    """
    try:
        # SentenceTransformer ëª¨ë¸ ì‚¬ìš© (ETF_AIì™€ ë™ì¼)
        from sentence_transformers import SentenceTransformer
        from sklearn.metrics.pairwise import cosine_similarity
        
        # ëª¨ë¸ ë¡œë“œ (ìºì‹±ì„ ìœ„í•´ ì „ì—­ ë³€ìˆ˜ë¡œ ê´€ë¦¬)
        if not hasattr(calculate_cosine_similarity, 'model'):
            logger.info("ğŸ¤– SentenceTransformer ëª¨ë¸ ë¡œë”© ì¤‘...")
            calculate_cosine_similarity.model = SentenceTransformer('paraphrase-MiniLM-L6-v2')
            logger.info("âœ… SentenceTransformer ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        model = calculate_cosine_similarity.model
        
        # ê° ë¬¸ì¥ ì¸ì½”ë”©
        sent1_encode = model.encode([text1])
        sent2_encode = model.encode([text2])
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = cosine_similarity(sent1_encode, sent2_encode)
        
        result = similarity[0][0]
        logger.debug(f"ğŸ“Š ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {result:.3f}")
        
        return result
        
    except ImportError:
        logger.error("âŒ SentenceTransformerê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ë¶ˆê°€")
        return 0.0
        
    except Exception as e:
        logger.error(f"âŒ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.0  # ì˜¤ë¥˜ ì‹œ 0 ë°˜í™˜

def extract_recommendation(analysis_result: str) -> str:
    """AI ë¶„ì„ ê²°ê³¼ì—ì„œ ì¶”ì²œì‚¬í•­ ì¶”ì¶œ"""
    try:
        # ê°„ë‹¨í•œ ì¶”ì²œì‚¬í•­ ì¶”ì¶œ ë¡œì§
        lines = analysis_result.split('\n')
        for line in lines:
            if any(word in line for word in ["ì¶”ì²œ", "ê¶Œì¥", "ì œì•ˆ", "ì¡°ì •", "ë³€ê²½"]):
                return line.strip()
        
        # ì¶”ì²œ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ì „ì²´ ê²°ê³¼ ë°˜í™˜ (ê¸¸ì´ ì œí•œ)
        if len(analysis_result) > 200:
            return analysis_result[:200] + "..."
        return analysis_result
        
    except Exception as e:
        logger.error(f"âŒ ì¶”ì²œì‚¬í•­ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return "AI ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

def extract_confidence_score(analysis_result: str) -> float:
    """AI ë¶„ì„ ê²°ê³¼ì—ì„œ ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ì¶œ (0.0 ~ 1.0)"""
    try:
        # ê°„ë‹¨í•œ ì‹ ë¢°ë„ ê³„ì‚° ë¡œì§
        confidence_score = 0.5  # ê¸°ë³¸ê°’
        
        # ë¶„ì„ ê²°ê³¼ì˜ ê¸¸ì´ì™€ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‹ ë¢°ë„ ì¡°ì •
        if len(analysis_result) > 100:
            confidence_score += 0.2
        
        if any(word in analysis_result for word in ["ë¶„ì„", "ë°ì´í„°", "ì •ë³´"]):
            confidence_score += 0.1
        
        if any(word in analysis_result for word in ["í™•ì‹¤", "ëª…í™•", "ë¶„ëª…"]):
            confidence_score += 0.1
        
        return min(confidence_score, 1.0)
        
    except Exception as e:
        logger.error(f"âŒ ì‹ ë¢°ë„ ì ìˆ˜ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
        return 0.5  # ê¸°ë³¸ê°’ ë°˜í™˜

def get_previous_analysis(user_id: int, etf_symbol: str, db) -> Optional[str]:
    """
    ì‚¬ìš©ìì˜ ì´ì „ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
    
    Args:
        user_id: ì‚¬ìš©ì ID
        etf_symbol: ETF ì‹¬ë³¼
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    
    Returns:
        ì´ì „ ë¶„ì„ ê²°ê³¼ ë˜ëŠ” None
    """
    try:
        # ìµœê·¼ AI ë¶„ì„ ì•Œë¦¼ ì¡°íšŒ
        notifications = get_user_notifications_by_type(
            db, user_id, NOTIFICATION_TYPES['AI_ANALYSIS'], limit=1
        )
        
        if notifications:
            # ì•Œë¦¼ ë‚´ìš©ì—ì„œ ë¶„ì„ ê²°ê³¼ ì¶”ì¶œ
            content = notifications[0].content
            # "ì¶”ì²œì‚¬í•­:" ì´í›„ ë¶€ë¶„ì´ ë¶„ì„ ê²°ê³¼ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ
            if "ì¶”ì²œì‚¬í•­:" in content:
                return content.split("ì¶”ì²œì‚¬í•­:")[0].strip()
            return content
        
        return None
        
    except Exception as e:
        logger.error(f"âŒ ì´ì „ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def save_analysis_result(user_id: int, etf_symbol: str, analysis_result: str, db) -> bool:
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ì„ì‹œ ì €ì¥ (ì„ íƒì‚¬í•­)
    
    Args:
        user_id: ì‚¬ìš©ì ID
        etf_symbol: ETF ì‹¬ë³¼
        analysis_result: ë¶„ì„ ê²°ê³¼
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
    
    Returns:
        ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ì—¬ê¸°ì„œëŠ” ì•Œë¦¼ í…Œì´ë¸”ì— ì €ì¥í•˜ì§€ë§Œ, 
        # í•„ìš”ì‹œ ë³„ë„ì˜ ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”ì„ ë§Œë“¤ ìˆ˜ ìˆìŒ
        logger.info(f"ğŸ’¾ {user_id} ì‚¬ìš©ìì˜ {etf_symbol} ë¶„ì„ ê²°ê³¼ ì €ì¥ë¨")
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        return False